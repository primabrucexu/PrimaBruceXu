# 八股文

![八股文](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/uPic/%E5%85%AB%E8%82%A1%E6%96%87.png)

---

## 1. Java

### 1.1 基础知识

#### 1.1.1 为什么说Java是编译与解释并存

> Java源代码需要先编译成字节码（class文件），然后再通过解释器来运行

- **编译型语言**

  通过编译器将源代码一次性翻译成可被该平台执行的机器码。一般情况下，编译语言的执行速度比较快，开发效率比较低。常见的编译性语言有 C、C++、Go、Rust 等等

- **解释性语言**

  通过解释器一句一句的将代码解释（interpret）为机器代码后再执行。解释型语言开发效率比较快，执行速度比较慢。常见的解释性语言有 Python、JavaScript、PHP 等等

![20211217105826](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/uPic/2022/06/06/20211217105826.png)

- **Java 程序从源代码到运行的过程如下图所示**

  ![20211217105907](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/uPic/2022/06/06/20211217105907.png)



#### 1.1.2 Java 基本类型有哪几种，各占多少位

| 基本类型 | 包装类型 | 2进制位数 | 占用空间(字节) |
| :------: | :------: | :-------: | :------------: |
|   int    | Integer  |    32     |       4        |
|   long   |   Long   |    64     |       8        |
|          |  Short   |    16     |       2        |
|   byte   |   Byte   |     8     |       1        |
|  float   |  Float   |    32     |       4        |
|  double  |  Double  |    64     |       8        |
|   char   |   Char   |    16     |       2        |
| boolean  | Boolean  |     1     |                |



#### 1.1.3 Java的泛型和擦除

- **泛型的本质**

  泛型的本质就是数据类型参数化，也就是说所操作的数据类型可以作为一个参数，从外部获取到

- **类型擦除**

  Java的泛型只存在与编译时，而在运行期间，其所含有的泛型信息将会被擦除，也就是所谓的类型擦除

  ~~~java
  public static void main(String[] args) throws Exception {
      List<Integer> list = new ArrayList<>();
      list.add(12);
      list.add("a");	// 这步操作会导致编译错误，因为Java的泛型约束在编译时还存在
      Class<? extends List> clazz = list.getClass();
      Method add = clazz.getDeclaredMethod("add", Object.class);
      add.invoke(list, "kl");	// 通过反射，可以在运行时进行操作，并且不会抛出异常。这说明了泛型信息在编译之后就被擦除了
      System.out.println(list);
  }
  ~~~



#### 1.1.4 `==` 和 `equals`

> `==` 一定 `equals`，但 `equals` 不一定 `==`

- `==`

  `==` 对于基本类型来说，比较的是值是否相同；对于引用数据类型，比较的是引用是否相同（对象的内存地址）

  > 因为 Java 只有值传递，所以，对于 `==` 来说，不管是比较基本数据类型，还是引用数据类型的变量，其本质比较的都是值，只是引用类型变量存的值是对象的地址。

- `equals`

  `equals`是对象专有的方法，用于比较两个对象是否相同，这里的比较逻辑可以自定义。其默认情况下则是比较两个对象的引用是否相同

  ~~~java
  // Object类的equals方法
  public boolean equals(Object obj) {
      return (this == obj);
  }
  ~~~



#### 1.1.5 `hashCode()` 和 `equals()`

- **hashCode**

  hashCode() 的作用是**获取哈希码**，也称为散列码；它实际上是返回一个int整数。这个**哈希码的作用**是确定该对象在哈希表中的索引位置。也就是说，**hashCode() 在散列表中才有用，在其它情况下没用**

  > hashcode的用途，实际上是给堆上的对象生成一个特征码。如果没有重写hashcode的话，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据）
  >
  > - hashcode的实际使用
      >
      >   当你把对象加入 `HashSet` 时，`HashSet` 会先计算对象的 `hashcode` 值来判断对象加入的位置，同时也会与其他已经加入的对象的 hashcode 值作比较，如果没有相符的 `hashcode`
      ，`HashSet` 会假设对象没有重复出现。但是如果发现有相同 `hashcode` 值的对象，这时会调用 `equals()` 方法来检查 `hashcode` 相等的对象是否真的相同。如果两者相同，`HashSet`
      就不会让其加入操作成功。如果不同的话，就会重新散列到其他位置。。这样我们就大大减少了 `equals` 的次数，相应就大大提高了执行速度

- **equals**

  equals是用来比较两个对象是否相同的

  > 关于更多详细解读，请参照https://www.cnblogs.com/skywang12345/p/3324958.html



#### 1.1.6 面向对象三大特性

- **封装**

  封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。就好像我们看不到挂在墙上的空调的内部的零件信息（也就是属性），但是可以通过遥控器（方法）来控制空调。如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。就好像如果没有空调遥控器，那么我们就无法操控空凋制冷，空调本身就没有意义了（当然现在还有很多其他方法
  ，这里只是为了举例子）

- **继承**

  对于某些具有共同点的子类，我们可以将其的共同之处抽取出来，作为父类。通过继承，以快速地创建新的类，可以提高代码的重用，程序的可维护性，节省大量创建新类的时间 ，提高我们的开发效率。

  ***注意点**：*

    1. 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，**只是拥有**。
    2. 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。
    3. 子类可以用自己的方式实现父类的方法。（以后介绍）。
    4. Java中，一个子类只能继承一个父类，但可以实现多个接口

- **多态**

  多态，顾名思义，表示一个对象具有多种的状态。具体表现为父类的引用指向子类的实例。

  ***特点***

    1. 对象之间具有父子关系（继承或实现）
    2. 多态调用方法的具体实现，只能在程序运行时确定
    3. 多态无法调用到子类存在而父类不存在的方法
    4. 如果子类重写了父类的方法，那么多态只能调用到子类重写后的方法



#### 1.1.7 面向对象和面向过程的区别

- **面向过程**

  着重于解决问题时的步骤（过程），只关注解决问题的方法

- **面向对象**

  关注解决问题时对象的变化，将变化抽象成对象的某个行为

> 由于面向对象多了一个抽象的过程，所以面向对象比面向过程更容易维护、复用和扩展



#### 1.1.8 反射

- **反射**

  通过反射，我们在运行时分析类以及执行类中的方法。通过反射，我们可以获取任意一个类的所有属性和方法并调用



#### 1.1.9 Java中形参和实参的传递方式：值传递

- 对于基础类型的参数，传递参数时传递的是变量值的副本
- 对于引用类型的参数，传递参数时传递的是对象在堆中地址的副本



#### 1.1.10 深拷贝和浅拷贝

![20211217150346](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/uPic/2022/06/06/20211217150346.png)



### 1.2 集合框架

#### 1.2.1 `List`、`Set`、`Queue`、`Map`

- **List**

  存储的元素是有序的、可重复的。

  > 实现类
  >
  > - ArrayList，动态数组
  > - Vector，线程安全的动态数组
  > - LinkedList，双向链表

- **Set**

  存储的元素是无序的、不可重复的。

  > 实现类
  >
  > - HashSet
  > - LinkedHashSet
  > - TreeSet

- **Queue**

  按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。

  > 实现类
  >
  > - PriorityQueue
  > - LinkedList
  > - ArrayDeque

- **Map**

  使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，"x" 代表 key，"y" 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。

  > 实现类
  >
  > - HashMap
  > - TreeMap



#### 1.2.2 `ArrayList` 和 `LinkedList`

- 数组和链表

  ArrayList是动态数组，LinkedList是双向链表

- 空间占用

  ArrayList会预留一定的多余空间，LinkedList则需要存放该节点的直接前驱和后继节点

- ArrayList实现了RamdomAccess，这在某些内部类的排序或者搜索时可以提高效率

  > 这个接口实际上没有任何实现，起到一个标识作用，表示该类具有随机访问的能力，主要目的是允许通用算法在应用于随机或顺序访问列表时改变其行为以提供良好的性能。



#### 1.2.3 ArrayList的扩容机制

- 以无参数构造方法创建 `ArrayList` 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为10。
- 每次当ArrayList需要扩容时，==容量增加倍率为1.5倍==



#### 1.2.4 比较 `HashSet`、`LinkedHashSet` 和 `TreeSet` 三者

- HashSet为无序的集合，LinkedHashSet保留了元素添加的顺序，TreeSet是可排序的集合



#### 1.2.5 `PriorityQueue`

- `PriorityQueue` 的元素出队顺序为与元素的优先级相关
- `PriorityQueue` 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据
- `PriorityQueue` 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。
- `PriorityQueue` 是非线程安全的，且不支持存储 `NULL` 和 `non-comparable` 的对象。
- `PriorityQueue` 默认是小顶堆，但可以接收一个 `Comparator` 作为构造参数，从而来自定义元素优先级的先后。



#### 1.2.6 `HashMap`、 `HashTable`、`HashSet`

- 除了HashTable都不是线程安全的，而HashTable性能堪忧，基本不用了
- HashSet可以简单的理解为HashMap的keySet
- HashMap支持Null的K和V，但只能有一个Null的K;HashSet支持一个Null的K;HashTable都不支持



#### 1.2.7 `HashMap`和`TreeMap`

- HashMap中的元素存放是无需的
- TreeMap的元素存放是有序的，同时支持搜索



#### 1.2.8 `HashMap`原理解读

- 底层数据结构：数组(桶) + 链表/红黑树

- 如何解决哈希冲突

  拉链法。JDK1.8后，当链表长度超过8且数组长度大于64时会转换成红黑树

- **loadFactor** 负载因子

  默认0.75。太小会导致空间利用率低，太高会导致查找时间效率低。不建议修改，默认的就挺好

- **capacity** 容量

  默认为16，任何HashMap的容量总是2的n次幂（如果在创建对象时通过构造函数指定了容量，则会扩容到最近的一个2的n次幂。例如指定了17，那么容量就是32

  > - 为什么是2的n次幂？
      >
  - 为了能让 HashMap 存取高效，尽量较少碰撞，也就是要尽量把数据分配均匀。我们上面也讲到了过了，Hash 值的范围值-2147483648 到 2147483647，前后加起来大概 40
    亿的映射空间，只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40
    亿长度的数组，内存是放不下的。所以这个散列值是不能直接拿来用的。用之前还要先做对数组的长度取模运算，得到的余数才能用来要存放的位置也就是对应的数组下标。这个数组下标的计算方法是“ `(n - 1) & hash`”。（n
    代表数组长度）。这也就解释了 HashMap 的长度为什么是 2 的幂次方。
    >
    >       **这个算法应该如何设计呢？**
    >
    >       我们首先可能会想到采用%取余的操作来实现。但是，重点来了：**“取余(%)操作中如果除数是 2 的幂次则等价于与其除数减一的与(&)操作（也就是说 hash%length==hash&(length-1)的前提是
    length 是 2 的 n 次方；）。”** 并且 **采用二进制位操作 &，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。**



#### 1.2.9 HashMap多线程情况下存在的问题

- 死循环。发生在扩容重新构建链表的时候
- 数据丢失。发生于同时put的元素hash值相同，

> ==HashMap在多线程中线程不安全的原因是可能存在多个线程同时向其中写入元素。所以在只读场景时，HashMap不会发生线程不安全的情况==
>
>   这里推荐在只读场景时，将HashMap转换成unmodifiableMap来避免错误的写操作



### 1.3 异步编程

#### 1.3.1 线程和进程的区别

- 进程是是系统运行程序的基本单位，线程是进程内部更小的运行单位。
- 进程和进程之间相互独立，进程内部的线程常常则会相互影响



#### 1.3.2 线程的生命周期和状态

|   状态名称    |                             说明                             |
| :-----------: | :----------------------------------------------------------: |
|      new      |       初始状态，线程被创建，但是还没有调用start()方法        |
|   runnable    |   运行状态，Java线程将操作系统中的就绪和运行统称为运行状态   |
|    blocked    |                   阻塞状态，通常是被锁阻塞                   |
|    waiting    | 等待状态，进入该状态表示当前线程需要等待其他线程做出一些特定动作（通知或中断） |
| Time_waitiing |              超时等待，可以在指定时间后自行返回              |
|  terminated   |                           终止状态                           |

- Java线程状态变迁

  ![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/uPic/2022/07/08/java-life-cycle.e81ded7b.png)



#### 1.3.3 死锁

> **产生死锁的四个必要条件**

1. 互斥条件：该资源任意一个时刻只由一个线程占用。
2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。

> **如何预防和避免死锁**

1. **破坏请求与保持条件** ：一次性申请所有的资源。
2. **破坏不剥夺条件** ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
3. **破坏循环等待条件** ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。



#### 1.3.4 sleep()方法和wait()方法

- sleep方法不会释放锁，wait方式释放了锁
- wait常用于线程之间的通信，sleep则通常被用于暂停执行
- 调用wait方法之后，线程不会自动苏醒，需要其他线程调用同一对象上的nofity方法或者notifyAll方法来唤醒。sleep方法在执行完成后，线程会自动苏醒。或者可以使用wait()方法来设定超时时间



#### 1.3.5 start()方法和run()方法的区别

new 一个 Thread，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()`
方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

- 总结：start才是开启 这个线程。然后调用run方法执行操作。直接调用run方法的话，会在当前线程中执行该方法mn



#### 1.3.6 synchronized关键字

- 使用机制

    1. **修饰实例方法:** 作用于当前对象实例加锁

       ```java
       synchronized void method() {
           //业务代码
       }
       ```

    2. **修饰静态方法:** 给类的class对象加锁

       ~~~java
       synchronized static void method() {
           //业务代码
       }
       
       ~~~

    3. **修饰代码块** ：指定加锁对象，对给定对象加锁

       ~~~java
       synchronized(object) {
           //业务代码
       }
       ~~~

- 锁的升级机制

  JDK1.6对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。

    - 无锁

    - 偏向锁

      对象处于偏向锁状态时，会在对象头中保留线程的id

      > 为什么会出现偏向锁：因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块的。

    - 轻量级锁

      轻量级锁时，资源的对象头中会保留指向线程栈的指针。当线程请求该资源时，会检查此信息。如果不匹配的话，则会自旋等待。当自旋次数到底阈值时，轻量级锁则会升级成重量级锁

    - 重量级锁

      重量级锁，是使用操作系统互斥量（`mutex`）来实现的传统锁。
      当所有对锁的优化都失效时，将退回到重量级锁。它与轻量级锁不同竞争的线程不再通过自旋来竞争线程，而是直接进入堵塞状态，此时不消耗CPU，然后等拥有锁的线程释放锁后，唤醒堵塞的线程，然后线程再次竞争锁。但是注意，当锁膨胀（`inflate`
      ）为重量锁时，就不能再退回到轻量级锁。



#### 1.3.7 volatile关键字

- 作用：禁止指令重排序优化；保证变量在线程于线程之间可见（每次访问时，线程都要从堆中获取最新的值）

  > synchronized和volatile的区别
  >
  > - volatile是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。
  > - volatile只能用于变量而synchronized可以修饰方法以及代码块 。
  > - volatile能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。
  > - volatile主要用于解决变量在多个线程之间的可见性，而 synchronized解决的是多个线程之间访问资源的同步性



#### 1.3.8 ThreadLocal

- 介绍：线程自己的专属本地变量

- 原理

  ~~~java
  public class Thread implements Runnable {
      //......
      //与此线程有关的ThreadLocal值。由ThreadLocal类维护
      ThreadLocal.ThreadLocalMap threadLocals = null;
  
      //与此线程有关的InheritableThreadLocal值。由InheritableThreadLocal类维护
      ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;
      //......
  }
  ~~~

  从`Thread`类源代码可以看出`Thread` 类中有一个`threadLocals`和 一个 `inheritableThreadLocals`变量，它们都是 `ThreadLocalMap`
  类型的变量,我们可以把 `ThreadLocalMap` 理解为`ThreadLocal` 类实现的定制化的 `HashMap`。默认情况下这两个变量都是 null，只有当前线程调用 `ThreadLocal` 类的 `set`
  或`get`方法时才创建它们，实际上调用这两个方法的时候，我们调用的是`ThreadLocalMap`类对应的 `get()`、`set()`方法。

  > 每个线程的本地变量，是存储在当前线程的ThreadLocalMap的，而不是ThreadLocal对象中的。

- ThreadLocal内存泄露问题

  ~~~java
  static class Entry extends WeakReference<ThreadLocal<?>> {
      /** The value associated with this ThreadLocal. */
      Object value;
  
      Entry(ThreadLocal<?> k, Object v) {
          super(k);
          value = v;
      }
  }
  ~~~
  
  `ThreadLocalMap`中使用的key为`ThreadLocal`的弱引用,而value是强引用。所以，如果`ThreadLocal`没有被外部强引用的情况下，在垃圾回收的时候，key
  会被清理掉，而value不会被清理掉。这样一来`ThreadLocalMap`中就会出现 key为null的Entry。假如我们不做任何措施的话value永远无法被GC回收，这个时候就可能会产生内存泄露。ThreadLocalMap
  实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后 最好手动调用`remove()`方法



#### 1.3.9 ThreadPoolExecutor

- 使用线程池的好处

    - **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    - **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
    - **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

- 构造方法参数详解

  ~~~java
  public ThreadPoolExecutor(int corePoolSize,
                            int maximumPoolSize,
                            long keepAliveTime,
                            TimeUnit unit,
                            BlockingQueue<Runnable> workQueue,
                            ThreadFactory threadFactory,
                            RejectedExecutionHandler handler) {
      if (corePoolSize < 0 ||
          maximumPoolSize <= 0 ||
          maximumPoolSize < corePoolSize ||
          keepAliveTime < 0)
          throw new IllegalArgumentException();
      if (workQueue == null || threadFactory == null || handler == null)
          throw new NullPointerException();
      this.corePoolSize = corePoolSize;
      this.maximumPoolSize = maximumPoolSize;
      this.workQueue = workQueue;
      this.keepAliveTime = unit.toNanos(keepAliveTime);
      this.threadFactory = threadFactory;
      this.handler = handler;
   }
  ~~~
  
  - corePoolSize：保留在池中的线程数，即使它们是空闲的，除非设置allowCoreThreadTimeOut
  - maximumPoolSize：池中允许的最大线程数
  - keepAliveTime：当线程数大于核心时，这是多余的空闲线程在终止前等待新任务的最长时间。
  - unit：keepAliveTime参数的时间单位
  - workQueue：用于在执行任务之前保存任务的队列。此队列将仅保存由execute方法提交的Runnable任务。
  - threadFactory：执行器创建新线程时使用的工厂
  - handler：如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时对于新添加任务的处理策略
    - `AbortPolicy`：抛出`RejectedExecutionException`
    - `CallerRunsPolicy`：调用添加者执行任务
    - `DiscardPolicy`：不处理新任务，直接丢弃掉。
    - `DiscardOldestPolicy`：丢弃最早的未处理的任务请求。
  
- execute()方法和submit()方法的区别

  1. **`execute()`方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功与否；**
  2. **`submit()`方法用于提交需要返回值的任务。线程池会返回一个 `Future` 类型的对象，通过这个 `Future` 对象可以判断任务是否执行成功**，并且可以通过 `Future` 的 `get()`方法来获取返回值，`get()`方法会阻塞当前线程直到任务完成，而使用 `get(long timeout，TimeUnit unit)`方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。

- 线程池执行任务流程图

  ![图解线程池实现原理](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091714480.png)

#### 1.3.10 AQS（todo）



---

## 2. JVM

### 2.1 内存模型

![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091734675.png)

![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091734400.png)



#### 2.1.1 程序计数器

程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。

为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各线程之间计数器互不影响，独立存储

> 注意 ：程序计数器是唯一一个不会出现 `OutOfMemoryError` 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。



#### 2.1.2 虚拟机栈

与程序计数器一样，Java虚拟机栈（后文简称栈）也是线程私有的，它的生命周期和线程相同，随着线程的创建而创建，随着线程的死亡而死亡。

栈绝对算的上是JVM运行时数据区域的一个核心，除了一些Native方法调用是通过本地方法栈实现的(后面会提到)，其他所有的Java方法调用都是通过栈来实现的（也需要和其他运行时数据区域比如程序计数器配合）。

方法调用的数据需要通过栈进行传递，每一次方法调用都会有一个对应的栈帧被压入栈中，每一个方法调用结束后，都会有一个栈帧被弹出。

栈由一个个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法返回地址。和数据结构上的栈类似，两者都是先进后出的数据结构，只支持出栈和入栈两种操作。

> 简单总结一下程序运行中栈可能会出现两种错误：
>
> - **`StackOverFlowError`：** 若栈的内存大小不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最大深度的时候，就抛出 `StackOverFlowError` 错误。
> - **`OutOfMemoryError`：** 如果栈的内存大小可以动态扩展， 如果虚拟机在动态扩展栈时无法申请到足够的内存空间，则抛出`OutOfMemoryError`异常。



#### 2.1.3 本地方法栈

和虚拟机栈所发挥的作用非常相似，区别是： **虚拟机栈为虚拟机执行 Java 方法 （也就是字节码）服务，而本地方法栈则为虚拟机使用到的 Native 方法服务。** 在 HotSpot 虚拟机中和 Java 虚拟机栈合二为一。

本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。

> 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 `StackOverFlowError` 和 `OutOfMemoryError` 两种错误。



#### 2.1.4 堆

Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。**此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。**

堆是垃圾收集器管理的主要区域，因此也被称作 **GC 堆（Garbage Collected Heap）**。从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点有：Eden、Survivor、Old 等空间。进一步划分的目的是更好地回收内存，或者更快地分配内存。

![hotspot-heap-structure](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091740370.png)

> 大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 S0 或者 S1，并且对象的年龄还会加 1(Eden区到Survivor区后对象的初始年龄变为1)，当它的年龄增加到一定程度（默认为 15岁），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 `-XX:MaxTenuringThreshold` 来设置。



#### 2.1.5 方法区

当虚拟机要使用一个类时，它需要读取并解析 Class 文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的**类信息、字段信息、方法信息、常量、静态变量、即时编译器编译后的代码缓存等数据**。

==相对来说，在方法区中较少发生GC，但是并不意味之永远不会发生GC==

> 方法区在jdk1.8之前的实现叫永久代，之后叫元空间。其中，方法区是一个抽象的概念，而永久代和元空间则是具体实现的名称

> 方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢？
>
> 判定一个常量是否是“废弃常量”比较简单，而要判定一个类是否是“无用的类”的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是 **“无用的类”** ：
>
> - 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
> - 加载该类的 `ClassLoader` 已经被回收。
> - 该类对应的 `java.lang.Class` 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。
>
> 虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。



#### 2.1.6 运行时常量池

Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量（Literal）和符号引用（Symbolic Reference）的常量池表(Constant Pool Table)。

字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量，符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。

常量池表会在类加载后存放到方法区的运行时常量池中。

运行时常量池的功能类似于传统编程语言的符号表，尽管它包含了比典型符号表更广泛的数据。

既然**运行时常量池是方法区的一部分**，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 `OutOfMemoryError` 错误。



#### 2.1.7 字符串常量池

**字符串常量池**是JVM为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。

JDK1.7之前，字符串常量池存放在永久代。JDK1.7后字符串常量池和静态变量从永久代移动了堆中。



### 2.2 GC

#### 2.2.1 如何判断对象已经死亡

##### 1 引用计数

给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。

**这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。**

##### 2 可达性分析

这个算法的基本思想就是通过一系列的称为**“GC Roots”**的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots没有任何引用链相连的话，则证明此对象是不可用的，需要被回收。

- **哪些对象可以作为 GC Roots 呢？**
  - 虚拟机栈(栈帧中的本地变量表)中引用的对象
  - 本地方法栈(Native方法)中引用的对象
  - 方法区中类静态属性引用的对象
  - 方法区中常量引用的对象
  - 所有被同步锁持有的对象

##### 3 Java中的引用

- **强引用（StrongReference）**

  以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。如果一个对象具有强引用，那就类似于**==必不可少的生活用品==**，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题

- **软引用（SoftReference）**

  如果一个对象只具有软引用，那就类似于**==可有可无的生活用品==**。如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。

- **弱引用（WeakReference）**

  如果一个对象只具有弱引用，那就类似于**==可有可无的生活用品==**。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于*垃圾回收器是一个优先级很低的线程*，因此不一定会很快发现那些只具有弱引用的对象。

- **虚引用（PhantomReference）**

  "虚引用"顾名思义，就是形同虚设，与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。

  **虚引用主要用来跟踪对象被垃圾回收的活动**。

  **虚引用与软引用和弱引用的一个区别在于：** 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。



#### 2.2.2 GC算法

- 标记清除

  该算法分为“标记”和“清除”阶段：首先标记出所有不需要回收的对象，在标记完成后统一回收掉所有没有被标记的对象。它是最基础的收集算法，后续的算法都是对其不足进行改进得到。这种垃圾收集算法会带来两个明显的问题：

  1. **效率问题**
  2. **空间问题（标记清除后会产生大量不连续的碎片）**

  ![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091803153.jpeg)

- 标记复制

  为了解决效率问题，“标记-复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。

  ![复制算法](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091803340.png)

- 标记整理

  根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。

  ![标记-整理算法 ](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091804528.png)



#### 2.2.3 垃圾收集器

|      收集器       | 收集区域 | GC算法   |    收集器类型    |                             说明                             |
| :---------------: | :------: | -------- | :--------------: | :----------------------------------------------------------: |
|      Serial       |  新生代  | 标记复制 |      单线程      |                                                              |
|      ParNew       |  新生代  | 标记复制 |    并行多线程    |                      Serial的多线程版本                      |
| Parallel Scavenge |  新生代  | 标记复制 |    并行多线程    |      比ParNew更关注吞吐量，并且可以调整停顿时间或吞吐量      |
|    Serial Old     |  老年代  | 标记整理 |      单线程      |                   Serial收集器的老年代版本                   |
|   Parallel Old    |  老年代  | 标记整理 |    并行多线程    | Parallel Scavenge的老年代版本，为了配合其面向吞吐量特性而开发的 |
|        CMS        |  老年代  | 标记清理 | 并行与并发多线程 |          尽可能的降低停顿时间，但会产生大量内存碎片          |
|        G1         | 跨代收集 |          |                  |                                                              |

> **并行和并发概念补充：**
>
> - **并行（Parallel）** ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。
> - **并发（Concurrent）**：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。

> CMS收集器
>
> ![CMS 垃圾收集器 ](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091827344.png)
>
> - **初始标记(stw)：**暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快；
> - **并发标记：**同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
> - **重新标记(stw)：**重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
> - **并发清除：**开启用户线程，同时 GC 线程开始对未标记的区域做清扫

> G1垃圾收集器
>
> - 内存结构
>
>   传统的GC收集器将连续的内存空间划分为新生代、老年代和永久代（JDK 8去除了永久代，引入了元空间Metaspace），这种划分的特点是各代的存储地址（逻辑地址，下同）是连续的。如下图所示：!![传统GC内存布局](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091847753.png)
>
>   传统GC内存布局
>
>   
>
>   而G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region，每个Region占有一块连续的虚拟内存地址。如下图所示：![g1 GC内存布局](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091847862.png)
>
>   
>
>   在上图中，我们注意到还有一些Region标明了H，它代表Humongous，这表示这些Region存储的是巨大对象（humongous object，H-obj），即大小大于等于region一半的对象。
>
> - 两个概念
>
>   - RememberSets，又叫Rsets是每个region中都有的一份存储空间，用于存储本region的对象被其他region对象的引用记录。
>   - CollectionSets，又叫Csets是一次GC中需要被清理的regions集合，注意G1每次GC不是全部region都参与的，可能只清理少数几个，这几个就被叫做Csets。
>
> - Young GC
>
>   年轻代的GC，StopTheWorld，复制算法。将E和S(from)区复制到S(to)，注意S(to)一开始是没有标识的，就是个free region。
>
>   ![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091853246.undefined)
>
>   ![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091853065.undefined)
>
> - Mix GX
>
>   1. 初次标记(stw)
>
>      标记GCroot直接引的对象和所在Region，但是与CMS不同的是，这里不止标记O区。注意初次标记一般和YGC同时发生，利用YGC的STW时间，顺带把这事给干了
>
>   2. RootRegion扫描
>
>      标记出RootRegion指向O区的region，标记这些region是为了降低并发标记的扫描范围，因为并发标记需要扫描GCROOT引用或间接的所有对象，而这些对象一定是在RootRegion出发指向的Region中的。MIXGC中Y区本来就要全扫，所以这里再按照O区过滤下，这样就缩小了扫描范围。该阶段的操作为遍历O区region查询Rset是否有来自RootRegion的，（RootRegion是初始标记得到的）
>
>   3. 并发标记
>
>      对整个堆进行标记
>
>   4. 重新标记
>
>      类似CMS，但也是整个堆
>
>   5. 复制/清理(stw)



### 2.3 类加载机制

#### 2.3.1 内置类加载器

1. **BootstrapClassLoader(启动类加载器)** ：最顶层的加载类，由 C++实现，负责加载 `%JAVA_HOME%/lib`目录下的 jar 包和类或者被 `-Xbootclasspath`参数指定的路径中的所有类。
2. **ExtensionClassLoader(扩展类加载器)** ：主要负责加载 `%JRE_HOME%/lib/ext` 目录下的 jar 包和类，或被 `java.ext.dirs` 系统变量所指定的路径下的 jar 包。
3. **AppClassLoader(应用程序类加载器)** ：面向我们用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类。



#### 2.3.2 双亲委派模型

在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载的时候，首先会把该请求委派给父类加载器的 `loadClass()` 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 `BootstrapClassLoader` 中。当父类加载器无法处理时，才由自己来处理。

![ClassLoader](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091922359.png)

- 使用双亲委派模型的优点
  - 避免了类的重复加载
  - 避免了核心类被篡改，保证了安全



---

## 3. 常用框架

### 3.1 Spring&SpringBoot

#### 3.1.1 IoC&AOP

##### 1 IoC

**IoC（Inverse of Control:控制反转）**是一种设计思想，而不是一个具体的技术实现。IoC的思想就是将原本在程序中手动创建对象的控制权，交由Spring框架来管理。

![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091933697.png)

将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。==这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来==。IoC容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。

##### 2 AOP

AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于==减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性==。

Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 **JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 **Cglib** 生成一个被代理对象的子类来作为代理，如下图所示

> 代理模式和装饰器模式的区别
>
> - 代理模式：为其他对象提供一种代理以控制对这个对象的访问.（换句话说，就是管控被代理的对象）
> - 装饰器模式可以动态的新增和组合对象的行为，用于增强自身功能，拓展自己的功能

> JDK动态代理和cglib代理的区别
>
> - JDK代理是面向接口的，通过反射机制来实现
> - cglib代理是面向class文件的字节码，通过修改字节码来实现代理功能



#### 3.1.2 Spring Bean

##### 1 Bean的作用域

- **singleton** : 唯一 bean 实例，Spring 中的 bean 默认都是单例的，对单例设计模式的应用。
- **prototype** : 每次请求都会创建一个新的 bean 实例。
- **request** : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。
- **session** : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。
- **global-session** ： 全局 session 作用域，仅仅在基于 portlet 的 web 应用中才有意义，Spring5 已经没有了。Portlet 是能够生成语义代码(例如：HTML)片段的小型 Java Web 插件。它们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话。

##### 2 Bean的生命周期

![image-20220709195436059](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091954106.png)

#### 3.1.3 SpringMVC

- 工作流程

  ![](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207091948055.png)



### 3.2 MyBatis

#### 3.2.1 #{}和${}的区别是什么？

- `${}`是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为`com.mysql.jdbc. Driver`。
- `#{}`是 sql 的参数占位符，MyBatis 会将 sql 中的`#{}`替换为? 号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的? 号占位符设置参数值，比如 ps.setInt(0, parameterValue)，`#{item.name}` 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 `param.getItem().getName()`。

#### 3.2.2 Mapper接口中的方法可以重载吗

可以，但是对于的xml映射文件中，不允许存在重复的id。示例如下

~~~java
/**
 * Mapper接口里面方法重载
 */
public interface StuMapper {
	List<Student> getAllStu();
	List<Student> getAllStu(@Param("id") Integer id);
}
~~~

~~~xml
<select id="getAllStu" resultType="com.pojo.Student">
    select * from student
    <where>
        <if test="id != null">
            id = #{id}
        </if>
    </where>
</select>
~~~

> Mapper接口方法可以重载，但是需要满足以下条件：
>
> 1. 仅有一个无参方法和一个有参方法
> 2. 多个有参方法时，参数数量必须一致。且使用相同的 `@Param` 

#### 3.2.3 为什么说MyBatis是半自动ORM映射工具？它与全自动的区别在哪里？

- Hibernate属于全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。
- MyBatis在查询关联对象或关联集合对象时，需要手动编写sql来完成，所以，称之为半自动 ORM 映射工具。

---

## 4. 常用中间件

### 4.1 MySQL

#### 4.1.1 基础架构

![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207092054552.png)

#### 4.1.2 MyISAM和InnoDB的区别是什么？

|                      | MyISAM | InnoDB |
| :------------------: | :----: | :----: |
|        行级锁        | 不支持 |  支持  |
|       支持事务       | 不支持 |  支持  |
|       支持外键       | 不支持 |  支持  |
| 异常崩溃后的安全恢复 | 不支持 |  支持  |

#### 4.1.3 事务

##### 1 ACID原则

1. **原子性**（`Atomicity`）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
2. **一致性**（`Consistency`）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；（事务最终要达成的目的）
3. **隔离性**（`Isolation`）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
4. **持久性**（`Durabilily`）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

##### 2 并发事务带来了哪些问题

- **脏读（Dirty read）:**

  ​	当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。

- **丢失修改（Lost to modify）:**

  ​	指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。

- **不可重复读（Unrepeatable read）:**

  ​	指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。

- **幻读（Phantom read）:** 

  ​	幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

> **不可重复读和幻读区别** ：不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次查询同一条查询语句（DQL）时，记录发现记录增多或减少了。

##### 3 事务隔离级别

1. **READ-UNCOMMITTED(读取未提交)**

   最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。

2. **READ-COMMITTED(读取已提交)**

   允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。

3. **REPEATABLE-READ(可重复读)**

   对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。

4. **SERIALIZABLE(可串行化)**

   最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

|     隔离级别     | 脏读 | 不可重复读 | 幻读 |
| :--------------: | :--: | :--------: | :--: |
| READ-UNCOMMITTED |  √   |     √      |  √   |
|  READ-COMMITTED  |  ×   |     √      |  √   |
| REPEATABLE-READ  |  ×   |     ×      |  √   |
|   SERIALIZABLE   |  ×   |     ×      |  ×   |

> **MySQL隔离级别的实现**：基于MVCC和锁



#### 4.1.4 索引

##### 1 优缺点

- 优点
  - 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。
  - 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
- 缺点
  - 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么索引也需要动态的修改，会降低 SQL 执行效率。
  - 索引需要使用物理文件存储，也会耗费一定空间。

##### 2 索引类型

> 实现索引的数据结构：哈希表和B/B+树

- 主键索引
- 二级索引（辅助索引）
  - 唯一索引
  - 普通索引
  - 前缀索引
  - 全文索引

##### 3 最左前缀匹配原则

在使用联合索引时，**MySQL** 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询，如 **`>`**、**`<`**、**`between`** 和 **`以%开头的like查询`** 等条件，才会停止匹配。



#### 4.1.5 SQL优化

- 避免使用通配符`*`
- 小表驱动大表。在连表查询时，尽量使用数据量小的表去过滤数据量大的表
- 利用 LIMIT 1 取得唯一行



### 4.2 Elasticsearch

#### 4.2.1 搜索原理 - 倒排索引

==倒排索引==

假设我们有两个文档，每个文档的正文字段如下：

-   The quick brown fox jumped over the lazy dog

-   Quick brown foxes leap over lazy dogs in summer


那么倒排索引之后的结果如下：

![20210705153127](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101543735.png)

现在我们要搜索 Quick brown只需要根据倒排索引之后的结果反向去查找文档即可：

![20210705153240](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101543208.png)

两个文档都匹配，如果我们仅从匹配数量来判断相关性来说，文档1比文档2更符合我们预期的搜索结果

> 快速搜索的原理
>
> 1. ==倒排索引在被写入磁盘后，是永远不可变的==，也就是它永远不能被修改。这种特性具有如下价值：
>
>    - 不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。
>    - 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。
>    - 其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。
>    - 写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和需要被缓存到内存的索引的使用量。
>
> 2. ES会在主分片及其所有副本分片上进行并行搜索，以加快搜索速度
>
>    

#### 4.2.2 集群健康状态

-   红色：至少存在一个主分片未分配
-   黄色：主分片均已分配，但至少一个副本未分配
-   绿色：everything is good

#### 4.2.3 数据写入流程

##### 1 从集群的角度看

1. 协调节点收到写入请求后，对文档进行路由，转发给相应的节点
2. 节点在主分片上写入内容，同时将数据同步给副本
3. 在一定数量的副本同步结束之后，返回写入成功

##### 2 从系统角度看

![img](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101625073.png)

1. 一个文档被索引之后，就会被添加到内存缓冲区，同时追加到了 translog

   ![20210706181147](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101609368.png)

2. 刷新（refresh）使分片处于提交的状态，分片每秒被刷新（refresh）一次：

   - 这些在内存缓冲区的文档被写入到一个新的段中，但没有进行 `fsync` 操作。
   - 这个段被打开，使其可被搜索。
   - 内存缓冲区被清空。

   ![20210706181231](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101551392.png)

3. 这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志

   ![20210706181257](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101551568.png)

4. 每隔一段时间，translog 变得越来越大，索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行：

   - 所有在内存缓冲区的文档都被写入一个新的段。
   - 缓冲区被清空。
   - 一个提交点被写入硬盘。
   - 文件系统缓存通过 `fsync` 被刷新（flush）。
   - 老的 translog 被删除。

![20210706181352](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101552813.png)



#### 4.2.4 集群master选举机制

##### 1 bully算法

**核心思想**

- 所有的节点都具有一个可以比较的ID，通过比较这个ID来选举master

**流程说明**

1. 节点向所有比自己ID大的节点发送选举信息（election），告诉他们我选你
2. 如果收到了回复消息（alive），这说明有人比自己“资历”更老，要让他去做老大，他只能乖乖等着老大选举
   1. 等待老大成功选举的消息（victory）
   2. 如果超时之后还没有成功选举消息，那么重新发送选举信息
3. 如果没有收到任何回复消息（alive），那么就自己当老大，同时向其他节点发送当选信息（victory）

##### 2 raft协议

**核心思想**

- raft算法首先将系统中角色定义为三种：leader、follower、candidate

- 每个leader都有一个任期（term），在它的任期内，他是老大；只要发现有人的任期比自己大，他就会无条件的加入

**选主流程**

1. follower在一段时间内没有收到leader发送来的确认信息之后会转变为candidate
2. candidate等待投票请求
   - 收到投票请求，投票，然后等待选举结果
   - 超时，给自己投票，发送投票请求
3. 收到足够投票请求后，成功当选leader，开始维护集群



#### 4.2.5 写入速度优化

- 调整translog刷新方式，提高translog刷新间隔

  ~~~yaml
  index.translog.durability: async
  index.translog.sync_interval: 5s
  index.translog.flush_threshold_size: 512mb
  ~~~

- 增大索引刷新间隔

  ~~~yaml
  index.refresh_interval: 1m
  ~~~

- 合理配置mapping，对于不需要建立索引的字段，index属性设置为no或者not_analyzed



#### 4.2.6 搜索速度优化

- 预留足够的内存空间
- 使用冗余字段来代替嵌套查询
- 对于几乎不怎么更新或者不再更新的索引执行强制段合并
- 限制搜索请求涉及到的分片数
- 限制深度分页



### 4.3 Kafka

#### 4.3.1 Kafka的消息模型

![发布订阅模型](https://cdn.jsdelivr.net/gh/primabrucexu/image@main/picgo/202207101627902.png)



#### 4.3.2 Zookeeper在Kafka集群中的作用

1. **Broker注册**：在Zookeeper上会有一个专门**用来进行Broker服务器列表记录**的节点。每个Broker在启动时，都会到Zookeeper上进行注册，即到`/brokers/ids`下创建属于自己的节点。每个Broker就会将自己的IP地址和端口等信息记录到该节点中去
2. **Topic注册**：在Kafka中，同一个**Topic的消息会被分成多个分区**并将其分布在多个Broker上，**这些分区信息及与Broker的对应关系**也都是由 Zookeeper在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
3. **负载均衡**：上面也说过了Kafka通过给特定Topic指定多个Partition, 而各个Partition可以分布在不同的 Broker上, 这样便能提供比较好的并发能力。 对于同一个Topic的不同Partition，Kafka会尽力将这些 Partition分布到不同的Broker服务器上。当生产者产生消息后也会尽量投递到不同Broker的Partition里面。当Consumer消费的时候，Zookeeper可以根据当前的Partition数量以及Consumer数量来实现动态负载均衡。

#### 4.3.3 Kafka为什么快

1. 多个分区并行处理
2. 顺序写入磁盘
3. 用了现代操作系统分页存储 Page Cache 来利用内存提高 I/O 效率
4. 采用了零拷贝技术 Producer 生产的数据持久化到 broker，采用 mmap 文件映射，实现顺序的快速写入 Customer 从 broker 读取数据，采用 sendfile，将磁盘文件读到 OS 内核缓冲区后，转到 NIO buffer 进行网络发送，减少 CPU 消耗

#### 4.3.4 Consumer Group

同一个topic的数据，会广播给不同的group；同一个group中的worker，只有一个worker能拿到这个数据。换句话说，对于同一个topic，每个group都可以拿到同样的所有数据，但是数据进入group后只能被其中的一个worker消费。group内的worker可以使用多线程或多进程来实现，也可以将进程分散在多台机器上，worker的数量通常不超过partition的数量，且二者最好保持整数倍关系，因为Kafka在设计时假定了一个partition只能被一个worker消费（同一group内）。

#### 4.3.5 Kafka怎么保证消息顺序

Kafka通过offset来保证每个partition中的消息顺序，但不能保证整个topic中的消息顺序。如果需要保证topic中的消息顺序，则需要设置partition为1





---



## 5 四大基础

### 5.1 数据结构

#### 5.1.1 红黑树

- 特点
  1. 每个节点非红即黑；
  2. 根节点总是黑色的；
  3. 每个叶子节点都是黑色的空节点（NIL节点）；
  4. 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
  5. 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）。





### 5.2 计算机网络

### 5.3 操作系统

### 5.4 算法
